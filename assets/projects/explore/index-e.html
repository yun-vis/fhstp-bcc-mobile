


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>

<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<style type="text/css">
.style1 {
				border-style: solid;
				border-width: 1px;
				padding: 1px 4px;
}
</style>
</head>
<body>

<div align="center">
<h1>Visualizing Bag-of-Features Image Categorization
    <br>Using Anchored Maps</h1>
<h3>
</h3>
<h3>
<a href="http://visual.k.u-tokyo.ac.jp/~gaoyi" target="_blank">Yi Gao</a>,
<a href="http://visual.k.u-tokyo.ac.jp/~yun" target="_blank">Hsiang-Yun Wu</a>,
<a href="http://www.cs.tsukuba.ac.jp/~misue" target="_blank">Kazuo Misue</a>,<br>
<a href="http://visual.k.u-tokyo.ac.jp/~mizunok/index-en.html" target="_blank">Kazuyo Mizuno</a>,
and
<a href="http://visual.k.u-tokyo.ac.jp/~shigeo/" target="_blank">Shigeo Takahashi</a>
</h3>
</div>

<div align="center">
<h3>The 7th International Symposium on Visualization & Interaction <br>
(VINCI 2014)</h3>
</div>

<div align="center">
<table style="width: 700px; height: 22px;">
  <tbody>
    <tr>
      <td>
<!-- ********** -->
<hr>
<!-- ********** -->
       This web page is prepared for providing research materials of our image categorization visualization project.
      </td>
    </tr>
  </tbody>
</table>
<br>
<br>

<div align="center">
<table style="width: 700px;">
 <tbody>
 <tr>
  <td>
   <!-- ********** -->
   <hr>
   <!-- ********** -->
   <h2>Introduction</h2>
<div style="text-align: justify;">

Developing effective visual categorization techniques is crucial to accelerate image retrieval from databases due to the rapidly increased data size. The bag-of-features (BoF) model is one of the most popular and promising approaches for extracting the underlying semantics from image databases. Nonetheless, the associated image categorization approaches based on machine learning techniques may not convince us of its validity since we cannot visually verify how the images have been classified in the high-dimensional image feature space.

Our work aims to visually rearrange the images in the projected feature space by taking advantage of a set of representative features called visual words obtained using the bag-of-features model. The main idea is to associate each image with a specific number of visual words to compose a bipartite graph, and then lay out the overall images using anchored map representation, as shown in Figure 1.

</table>
<br>
<!-- ############################## -->
    <table style="width: 700px;">
<!-- -->
    <tr>
        <td align=center>
            <a href="bipartite.png"><img src="bipartite.png" width="230" height="215"></a>
        </td>
        <td align=center>
            <a href="sparse.png"><img src="sparse.png" width="230" height="215"></a><br>
        </td>
        <td align=center>
            <a href="anchoredmap.png"><img src="anchoredmap.png" width="230" height="215"></a>
        </td>
    </tr>
    <tr>
        <td align=center>
            (a) An original bipartite graph
        </td>
        <td align=center>
            (b) A sparse bipartite graph after edge pruning
        </td>
        <td align=center>
            (c) The corresponding anchored map representation
        </td>
    </tr>
    <tr>
        <td align=center colspan=3>
            Figure 1: Bipartite relationships between images and visual words in the BoF model.
        </td>
    </tr>
</table>
</div>
</td>
</tr>
</tbody>
</table>
</div>


<br>
<div align="center">
<table style="width: 700px;">
 <tbody>
 <tr>
  <td>
    <div style="text-align: left;">
    <!-- ********** -->
    <hr>
    <!-- ********** -->
    <h2>Method</h2>
    </div>
</td>
</tr>
</tbody>
</table>
<div align="center">
<table style="width: 700px;">
 <tbody>
 <tr>
  <td>
<div style="text-align: justify;">
    Each image is represented as a sparse vector of visual words in BoF model, as shown in Figure 2. We associate each image with a specific number of visual words to compose a bipartite graph, and then layout the overall set of images using anchored map representation in which the ordering of anchor nodes is optimized through a genetic algorithm. For handling relatively large image datasets, we adaptively merge a pair of most similar images one by one to conduct the hierarchical clustering through the similarity measure based on the weighted Jaccard coefficient. Voronoi partitioning has been also incorporated into our approach so that we can visually identify the image categorization based on support vector machine.
</div>
</td>
  </table>
<br>
<!-- ############################## -->
<table>
<!-- -->
    <tr>
        <td align=center>
            <a href="feature.png"><img src="feature.png" width="600" height="247"></a>
        </td>

    </tr>
    <tr>
        <td align=center>
            Figure 2. The overview of the Bags-of-Features model
        </td>

    </tr>
</table>
</tr>
</tbody>
</table>
<br>

<div align="center">
<table style="width: 700px;">
 <tbody>
 <tr>
  <td>
   <!-- ********** -->
   <hr>
   <!-- ********** -->
   <h2>Results</h2>
<div style="text-align: left;">
Here, we present several results that are generated from our system.
<br>
(You can click the thumbnail image for that of the original resolution.)
</div>
</td>
</tr>
</tbody>
</table>
<br><br>
<!-- ############################## -->
<table style="width: 700px;">
<!-- -->
    <tr>
        <td align=center>
            <a href="simple-initial-network.png"><img src="simple-initial-network.png" width="350"></a>
        </td>
        <td align=center>
            <a href="simple-reordered-network.png"><img src="simple-reordered-network.png" width="350"></a><br>
        </td>
    </tr>
    <tr>
        <td align=center>
            (a) Original layout.
        </td>
        <td align=justify>
            (b) Enhanced layout with an optimized circular ordering of visual words annotated with representative images. Images in same category are brought closer to each other.
        </td>
    </tr>
</table>

<br>
<table style="width: 700px;">
    <tr>
        <td align=justify>
            Figure 3: Using anchored maps to visualize the bag-of-features image categorization for coin and eyeglass images. ( #{input images} = 20, #{visual words} = 24. )
        </td>
    </tr>
</table>

<!-- ############################## -->
<table style="width: 700px;">
<!-- -->
    <tr>
        <td align=center>
            <a href="category-3-L1-region.png"><img src="category-3-L1-region.png" width="350"></a>
        </td>
        <td align=center>
            <a href="category-3-L3-region.png"><img src="category-3-L3-region.png" width="350"></a><br>
        </td>
    </tr>
    <tr>
        <td align=center>
            (a) 10% of images.
        </td>
        <td align=center>
            (b) 30% of images.
        </td>
    </tr>
    <tr>
        <td align=center>
            <a href="category-3-L4-region.png"><img src="category-3-L4-region.png" width="350"></a>
        </td>
        <td align=center>
            <a href="category-3-all-region.png"><img src="category-3-all-region.png" width="350"></a><br>
        </td>
    </tr>
    <tr>
        <td align=center>
            (c) 40% of images.
        </td>
        <td align=center>
            (d) 100% of images.
        </td>
    </tr>
</table>

<br>
<table style="width: 700px;">
    <tr>
        <td align=justify>
            Figure 4: Discriminating car images using the support vector machine at multiple hierarchical levels. Images of the training set are labeled as red (car images) and blue (others). The inferred region of the car images is rendered in yellow through the Voronoi tessellation. ( #{input images} = 240, #{visual words} = 100. )
        </td>
    </tr>
</table>

<!-- ############################## -->
<table style="width: 700px;">
<!-- -->
    <tr>
        <td align=center>
            <a href="multiple-L3-region.png"><img src="multiple-L3-region.png" width="350"></a>
        </td>
        <td align=center>
            <a href="multiple-L8-region.png"><img src="multiple-L8-region.png" width="350"></a><br>
        </td>
    </tr>
    <tr>
        <td align=center>
            (a) Coarse level.
        </td>
        <td align=center>
            (b) Fine level.
        </td>
    </tr>
</table>

<br>
<table style="width: 700px;">
    <tr>
        <td align=justify>
            Figure 5: This experiment demonstrates how we can categorize images of a specific category even when we train our image classifier indirectly with similar looking images. In this experiment, we represent each image in terms of visual words obtained from training images containing tomatoes, coins, and cars and try to collect images of round shapes. However, we also take as input images of additional categories such as CDs and glasses in this example. ( #{input images} = 420. #{visual words} = 100. )
        </td>
    </tr>
</table>

<br>
<table width="700">
  <tbody>
    <tr>
      <td>
<!-- ********** -->
<hr>
<!-- ********** -->
       <h2>Paper &amp; Video</h2>
      <h4><span style="font-weight: normal;">
Yi Gao, Hsiang-Yun Wu, Kazuo Misue, Kazuyo Mizuno, and Shigeo Takahashi: Visualizing Bag-of-Features Image Categorization using Anchored Maps, <a href="http://vinci-conf.org/" target="_blank">the 7th International Symposium on Visual Information Communication and Interaction (VINCI 2014)</a>, 2014.
</span>
      <a href="vinci2014.pdf">Paper-preprint (PDF, 9.2MB)</a><span style="font-weight: normal;">, </span>
      <a href="vinci2014.mov">Video(MOV, 19.5MB)</a>
      </h4>
      </td>
    </tr>
  </tbody>
</table>
</div>

<hr>
<hr>
Last Modified: July 18, 2014
</body>
</html>
